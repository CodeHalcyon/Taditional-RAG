Hereâ€™s a clean, well-structured **README.md** file for your RAG (Retrieval-Augmented Generation) pipeline project built with LangChain, ChromaDB, and Gemini:

---

# ğŸ“˜ PDF RAG Pipeline using LangChain, ChromaDB, and Gemini

This project demonstrates how to build a **Retrieval-Augmented Generation (RAG)** pipeline from scratch using a **PDF document** as the knowledge base.
It loads a PDF, splits it into chunks, embeds it using a SentenceTransformer model, stores it in **ChromaDB**, retrieves relevant chunks for a query, and finally generates an enhanced response using **Googleâ€™s Gemini model**.

---

## ğŸš€ Features

* **PDF Loading** using `PyMuPDFLoader`
* **Text Chunking** with `CharacterTextSplitter`
* **Semantic Embeddings** using `SentenceTransformer (all-MiniLM-L6-v2)`
* **Vector Storage** and **Retrieval** using `ChromaDB`
* **Context-Aware Responses** generated by **Gemini LLM (gemini-2.5-flash)**
* Modular design with custom classes:

  * `EmbeddingManager` â€“ for handling embeddings
  * `VectorStorage` â€“ for ChromaDB operations
  * `ragretriver` â€“ for context retrieval
  * `rag_res` â€“ for generating LLM-based responses

---

## ğŸ§© Project Structure

```
project/
â”‚
â”œâ”€â”€ cc2.pdf                     # Your input PDF file
â”œâ”€â”€ main.ipynb / script.py      # Main pipeline script
â”œâ”€â”€ data/
â”‚   â””â”€â”€ vector_store/           # Persistent ChromaDB store
â”œâ”€â”€ .env                        # Environment variables (for Google API Key)
â””â”€â”€ README.md                   # Project documentation
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/yourusername/pdf-rag-pipeline.git
cd pdf-rag-pipeline
```

### 2ï¸âƒ£ Create a virtual environment and install dependencies

```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Install dependencies manually (if no requirements.txt)

```bash
pip install langchain langchain-community langchain-text-splitters chromadb sentence-transformers numpy python-dotenv langchain-google-genai
```

### 4ï¸âƒ£ Set up environment variables

Create a `.env` file in the project root with your **Google API Key**:

```
GOOGLE_API_KEY=your_api_key_here
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Load and Process PDF

```python
from langchain_community.document_loaders import PyMuPDFLoader
loader = PyMuPDFLoader("cc2.pdf")
docs = loader.load()
```

### 2ï¸âƒ£ Split Text into Chunks

```python
from langchain_text_splitters import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = text_splitter.split_documents(docs)
```

### 3ï¸âƒ£ Generate Embeddings

```python
embed_manager = EmbeddingManager()
embeddings = embed_manager.generate_embeddings([chunk.page_content for chunk in chunks])
```

### 4ï¸âƒ£ Store in ChromaDB

```python
vector_store = VectorStorage()
vector_store.add_documents(chunks, embeddings)
```

### 5ï¸âƒ£ Retrieve Context

```python
retriever = ragretriver(vector_store, embed_manager)
results = retriever.retrieve("Explain the characteristics of PaaS")
```

### 6ï¸âƒ£ Generate Final Answer via LLM

```python
from langchain_google_genai import ChatGoogleGenerativeAI
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

response = rag_res("Explain the characteristics of PaaS", retriever, llm)
print(response)
```

---

## ğŸ§± Class Overview

### ğŸ”¹ `EmbeddingManager`

Handles loading and using a SentenceTransformer model for embedding generation.

### ğŸ”¹ `VectorStorage`

Manages creation and persistence of ChromaDB collections for efficient document similarity search.

### ğŸ”¹ `ragretriver`

Retrieves top matching document chunks for a given query using cosine similarity.

### ğŸ”¹ `rag_res`

Combines retrieval and LLM response generation into a simple RAG pipeline.

---

## Example Output

**Query:**

> "Briefly explain the characteristics of PaaS."

**Response:**

> "PaaS provides a platform with tools, runtime environments, and frameworks that allow developers to build, test, and deploy applications without managing infrastructure. It offers scalability, integration, and automated deployment features."

---

## âš ï¸ Notes

* Make sure you have a valid **Google Generative AI API Key** for the Gemini model.
* ChromaDB will automatically persist your vector store in `./data/vector_store`.
* Adjust `chunk_size` and `chunk_overlap` for optimal retrieval performance depending on your document type.
* Make sure you are using python version 3.10 or less or else you will face error in using chromadb.

---

## ğŸ‘¨â€ğŸ’» Author

**Chetan Sirigiri**
ğŸ“§ [chetandev0109@gmail.com](mailto:chetandev0109@gmail.com)
ğŸŒ [LinkedIn](https://www.linkedin.com/in/chetan-sirigiri) | [GitHub](https://github.com/codehalcyon)
